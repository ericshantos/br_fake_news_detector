{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "cellView": "form",
        "id": "0A2psQ9wkKv_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#@title The MIT License (MIT)\n",
        "#\n",
        "# Copyright (c) 2024 Eric dos Santos.\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "# THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__vplneBkhrq"
      },
      "source": [
        "# Fake News Classification System\n",
        "\n",
        "This project aims to develop a neural network for detecting fake news in Portuguese, using the dataset [Fake.br-Corpus](https://github.com/roneysco/Fake.br-Corpus). With this, we seek to create a system capable of identifying patterns and distinguishing fake news from real news, contributing to the fight against misinformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbMFa6CEBg_M"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"center\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ericshantos/br_fake_news_detector_model/blob/main/br_fake_news_detector_model.ipynb\n",
        "\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run on Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ericshantos/br_fake_news_detector_model/blob/main/br_fake_news_detector_model/br_fake_news_detector_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View the code on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSx8er0qkk-f"
      },
      "source": [
        "## Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3oc9DOJISWn",
        "outputId": "abc08fe1-ecee-4799-b465-a2894b6e7e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Fake.br-Corpus' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/roneysco/Fake.br-Corpus\n",
        "DATA_PATH = \"./Fake.br-Corpus/full_texts\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bZmwUyTf8xcp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# News Directory\n",
        "fake_dir = f\"{DATA_PATH}/fake\"\n",
        "real_dir = f\"{DATA_PATH}/true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99mmIko9Fwoq"
      },
      "source": [
        "### News content extraction:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eroFrkQJbCMF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def load_news(news_dir: str, label: str) -> pd.DataFrame:\n",
        "    # List to store news\n",
        "    news = []\n",
        "\n",
        "    # Cycle through all files in the specified directory\n",
        "    for filename in os.listdir(news_dir):\n",
        "        # Checks if the file has the .txt extension\n",
        "        if filename.endswith(\".txt\"):\n",
        "            # Gets the full path of the file\n",
        "            file_path = os.path.join(news_dir, filename)\n",
        "\n",
        "            # Open the file and read its contents\n",
        "            with open(file_path, \"r\") as file:\n",
        "                content = file.read()\n",
        "\n",
        "                # Adds the content and label to the news list\n",
        "                news.append({\"text\": content, \"label\": label})\n",
        "\n",
        "    # Returns a pandas DataFrame containing the news\n",
        "    return pd.DataFrame(news)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfJq8ohRb_uz"
      },
      "source": [
        "Result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nm6aTvsicB6f"
      },
      "outputs": [],
      "source": [
        "fake_news = load_news(fake_dir, 0)\n",
        "real_news = load_news(real_dir, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROaBKDzaR8wL"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFMd18ZPTBNz"
      },
      "source": [
        "### Concatenate the DataFrames\n",
        "\n",
        "Group Dataframes to generate a single robust database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "31gJ9BtPVyw8"
      },
      "outputs": [],
      "source": [
        "data_news = pd.concat([fake_news, real_news], ignore_index=True).sample(frac=1, random_state=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO_NWvm4WnFb"
      },
      "source": [
        "Final base information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwLb0lbYNO0Q",
        "outputId": "cf7357ab-9385-4858-ca61-bc6e49238da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 7200 entries, 3248 to 338\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    7200 non-null   object\n",
            " 1   label   7200 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 168.8+ KB\n"
          ]
        }
      ],
      "source": [
        "data_news.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lUB-N1znrzs",
        "outputId": "0ca01d74-4de1-4814-bdd5-71da3cc7cb20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text      object\n",
            "label    float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "data_news = data_news.apply(\n",
        "\n",
        "    # If valid, type the column as float\n",
        "    lambda col: col.astype(float) if col.apply(\n",
        "\n",
        "        # Check if they are digits\n",
        "        lambda x: str(x).replace('.', '', 1).isdigit()\n",
        "    ).all() else col\n",
        ")\n",
        "\n",
        "# Result\n",
        "print(data_news.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eulKWpHUd7N6"
      },
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qSuQr25Vd_Lc"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download pt_core_news_sm > /dev/null 2>&1\n",
        "!pip install unidecode > /dev/null 2>&1\n",
        "\n",
        "from unidecode import unidecode\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "  # Text processing\n",
        "  doc = nlp(text)\n",
        "\n",
        "  # Tokenization, stopword removal, punctuation and accentuation\n",
        "  tokens = [unidecode(token.lemma_) for token in doc if not token.is_stop and not token.is_punct]\n",
        "\n",
        "  return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvZtWBPrnrwh"
      },
      "source": [
        "Clear news content:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "L9G4v-2Anwos"
      },
      "outputs": [],
      "source": [
        "data_news[\"text\"] = data_news[\"text\"].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLdX7o7YYw_N",
        "outputId": "d53119ab-862f-4a3c-e3a2-3a2506240a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 7200 entries, 3248 to 338\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   text    7200 non-null   object \n",
            " 1   label   7200 non-null   float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 168.8+ KB\n"
          ]
        }
      ],
      "source": [
        "data_news.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuQ3WkgqIsBI"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8OxbRGqSIuh7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tokenizer Object\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "\n",
        "tokenizer.fit_on_texts(data_news['text'])\n",
        "\n",
        "# Converting texts into sequences of numbers\n",
        "sequences = tokenizer.texts_to_sequences(data_news['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Y-s9O-XQWK"
      },
      "source": [
        "### Prepares the labels and data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SqhrN-rYXbL0"
      },
      "outputs": [],
      "source": [
        "# Transform the texts into sequences of numbers\n",
        "X = pad_sequences(sequences, maxlen=200)\n",
        "\n",
        "# news labels(fake or real)\n",
        "y = data_news[\"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiII8APuYGvQ"
      },
      "source": [
        "### Splitting the dataset into training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJt1LgGsYK7z",
        "outputId": "28493f4f-7c4b-4fd8-f906-c4bad22c566a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (5760, 200)\n",
            "Test set size: (1440, 200)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splits data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYuO9WkZfP7-"
      },
      "source": [
        "### Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbD9hBQHfexY",
        "outputId": "8bbe535b-83ad-4c64-bf49-42f254403220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "  # Convert tokens to dense vectors: input layer\n",
        "  Embedding(input_dim=10000, output_dim=128, input_length=200),\n",
        "\n",
        "  # Hidden layers\n",
        "  LSTM(128, return_sequences=True),\n",
        "  Dropout(0.2),\n",
        "  LSTM(64, return_sequences=True),\n",
        "  Dropout(0.2),\n",
        "  LSTM(32),\n",
        "\n",
        "  # Output Layer\n",
        "  Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3Cz-_IghY2x"
      },
      "source": [
        "**Model compilation**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "48Xru8lehe4_"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT5eiqtmjGyW"
      },
      "source": [
        "### Treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwONYo0NjKca",
        "outputId": "14f6ef7c-e979-4629-9f40-eeb80783d58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.7398 - loss: 0.4823 - val_accuracy: 0.9389 - val_loss: 0.2268\n",
            "Epoch 2/5\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9444 - loss: 0.2152 - val_accuracy: 0.9389 - val_loss: 0.2260\n",
            "Epoch 3/5\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9441 - loss: 0.2159 - val_accuracy: 0.9389 - val_loss: 0.2270\n",
            "Epoch 4/5\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.9439 - loss: 0.2152 - val_accuracy: 0.9389 - val_loss: 0.2297\n",
            "Epoch 5/5\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.9481 - loss: 0.2044 - val_accuracy: 0.9389 - val_loss: 0.2298\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLE2D3OfkfJJ"
      },
      "source": [
        "#### Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N7CTarUkhRI",
        "outputId": "df6b0071-ae06-4b6d-e0a9-6bdef4b01044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - accuracy: 0.9252 - loss: 0.2690\n",
            "Loss: 0.22978998720645905, Accuracy: 0.9388889074325562\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hh3xnDMBj-s"
      },
      "source": [
        "### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "jRHqOJZgBmza"
      },
      "outputs": [],
      "source": [
        "model.save(\"br_fake_news_predict_model.keras\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}