{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0A2psQ9wkKv_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#@title The MIT License (MIT)\n",
        "#\n",
        "# Copyright (c) 2024 Eric dos Santos.\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "# THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sistema de Classificação de Notícias Falsas\n",
        "\n",
        "Este projeto tem como objetivo desenvolver uma rede neural para detecção de fake news em língua portuguesa, utilizando o dataset [Fake.br-Corpus](https://github.com/roneysco/Fake.br-Corpus). Com isso, buscamos criar um sistema capaz de identificar padrões e distinguir notícias falsas de verdadeiras, contribuindo para o combate à desinformação."
      ],
      "metadata": {
        "id": "__vplneBkhrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"center\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ericshantos/br_fake_news_detector_model/blob/main/br_fake_news_detector_model.ipynb\n",
        "\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Rode no Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ericshantos/br_fake_news_detector_model/blob/main/br_fake_news_detector_model/br_fake_news_detector_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Visualize o código no GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "BbMFa6CEBg_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregamento do dataset"
      ],
      "metadata": {
        "id": "eSx8er0qkk-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/roneysco/Fake.br-Corpus\n",
        "DATA_PATH = \"./Fake.br-Corpus/full_texts\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3oc9DOJISWn",
        "outputId": "b173a406-0799-4994-a329-18cf8aa6dd1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Fake.br-Corpus'...\n",
            "remote: Enumerating objects: 28763, done.\u001b[K\n",
            "remote: Total 28763 (delta 0), reused 0 (delta 0), pack-reused 28763 (from 1)\u001b[K\n",
            "Receiving objects: 100% (28763/28763), 37.10 MiB | 14.56 MiB/s, done.\n",
            "Resolving deltas: 100% (14129/14129), done.\n",
            "Updating files: 100% (21602/21602), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Diretório de notícias\n",
        "fake_dir = f\"{DATA_PATH}/fake\"\n",
        "real_dir = f\"{DATA_PATH}/true\""
      ],
      "metadata": {
        "id": "bZmwUyTf8xcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extração do conteúdo das notícias:\n"
      ],
      "metadata": {
        "id": "99mmIko9Fwoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def load_news(news_dir: str, label: str) -> pd.DataFrame:\n",
        "    # Lista para armazenar as notícias\n",
        "    news = []\n",
        "\n",
        "    # Percorre todos os arquivos no diretório especificado\n",
        "    for filename in os.listdir(news_dir):\n",
        "        # Verifica se o arquivo tem a extensão .txt\n",
        "        if filename.endswith(\".txt\"):\n",
        "            # Obtém o caminho completo do arquivo\n",
        "            file_path = os.path.join(news_dir, filename)\n",
        "\n",
        "            # Abre o arquivo e lê seu conteúdo\n",
        "            with open(file_path, \"r\") as file:\n",
        "                content = file.read()\n",
        "\n",
        "                # Adiciona o conteúdo e o rótulo à lista de notícias\n",
        "                news.append({\"text\": content, \"label\": label})\n",
        "\n",
        "    # Retorna um DataFrame do pandas contendo as notícias\n",
        "    return pd.DataFrame(news)"
      ],
      "metadata": {
        "id": "eroFrkQJbCMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultado:"
      ],
      "metadata": {
        "id": "SfJq8ohRb_uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_news = load_news(fake_dir, 0)\n",
        "real_news = load_news(real_dir, 1)"
      ],
      "metadata": {
        "id": "nm6aTvsicB6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pré-processamento dos dados"
      ],
      "metadata": {
        "id": "ROaBKDzaR8wL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Concatenar os DataFrames\n",
        "\n",
        "Agrupar os Dataframes para gerar uma única base de dados robusta."
      ],
      "metadata": {
        "id": "IFMd18ZPTBNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_news = pd.concat([fake_news, real_news], ignore_index=True).sample(frac=1, random_state=13)"
      ],
      "metadata": {
        "id": "31gJ9BtPVyw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Informações sobre a base final:"
      ],
      "metadata": {
        "id": "ZO_NWvm4WnFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_news.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwLb0lbYNO0Q",
        "outputId": "979e0296-e704-4dd0-8a4b-5b3826a79d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 7200 entries, 3248 to 338\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    7200 non-null   object\n",
            " 1   label   7200 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 168.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_news = data_news.apply(\n",
        "\n",
        "    # Caso válido, tipa a coluna como float\n",
        "    lambda col: col.astype(float) if col.apply(\n",
        "\n",
        "        # Verifica se são dígitos\n",
        "        lambda x: str(x).replace('.', '', 1).isdigit()\n",
        "    ).all() else col\n",
        ")\n",
        "\n",
        "# Resultado\n",
        "print(data_news.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lUB-N1znrzs",
        "outputId": "f67493da-5f92-49c2-81d6-8b4c7552ccc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text      object\n",
            "label    float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limpeza de dados"
      ],
      "metadata": {
        "id": "eulKWpHUd7N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm > /dev/null 2>&1\n",
        "!pip install unidecode > /dev/null 2>&1\n",
        "\n",
        "from unidecode import unidecode\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "  # Processamento do texto\n",
        "  doc = nlp(text)\n",
        "\n",
        "  # Tokenização, remoção de stopwords, pontuação e acentuação\n",
        "  tokens = [unidecode(token.lemma_) for token in doc if not token.is_stop and not token.is_punct]\n",
        "\n",
        "  return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "qSuQr25Vd_Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpar conteúdo das notícia:"
      ],
      "metadata": {
        "id": "hvZtWBPrnrwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_news[\"text\"] = data_news[\"text\"].apply(clean_text)"
      ],
      "metadata": {
        "id": "L9G4v-2Anwos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_news.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLdX7o7YYw_N",
        "outputId": "2c0b97d3-d998-4f28-dd0a-c6221c36d1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 7200 entries, 3248 to 338\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   text    7200 non-null   object \n",
            " 1   label   7200 non-null   float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 168.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento"
      ],
      "metadata": {
        "id": "vuQ3WkgqIsBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Objeto Tokenizer\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "\n",
        "tokenizer.fit_on_texts(data_news['text'])\n",
        "\n",
        "# Conversão dos textos em sequências de números\n",
        "sequences = tokenizer.texts_to_sequences(data_news['text'])"
      ],
      "metadata": {
        "id": "8OxbRGqSIuh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepara os rótulos e dados para treinamento"
      ],
      "metadata": {
        "id": "-9Y-s9O-XQWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforma os textos\n",
        "X = pad_sequences(sequences, maxlen=200)\n",
        "\n",
        "# Rótulos das notícias (fake ou real)\n",
        "y = data_news[\"label\"]"
      ],
      "metadata": {
        "id": "SqhrN-rYXbL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divisão do conjunto de dados em treino e teste"
      ],
      "metadata": {
        "id": "DiII8APuYGvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divide os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJt1LgGsYK7z",
        "outputId": "f26150c1-47ca-4f73-b9a5-d026d55a9a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: (5760, 200)\n",
            "Tamanho do conjunto de teste: (1440, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arquitetura do modelo"
      ],
      "metadata": {
        "id": "qYuO9WkZfP7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  # Converte tokens em vetores densos: camada de entrada\n",
        "  Embedding(input_dim=10000, output_dim=128, input_length=200),\n",
        "\n",
        "  # Camadas ocultas\n",
        "  LSTM(128, return_sequences=True),\n",
        "  Dropout(0.2),\n",
        "  LSTM(64, return_sequences=True),\n",
        "  Dropout(0.2),\n",
        "  LSTM(32),\n",
        "\n",
        "  # Camada de saída\n",
        "  Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbD9hBQHfexY",
        "outputId": "8b15f246-5cd9-4b2d-ec33-8cf003a943da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compilação do modelo**:"
      ],
      "metadata": {
        "id": "g3Cz-_IghY2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "48Xru8lehe4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinando o modelo"
      ],
      "metadata": {
        "id": "PT5eiqtmjGyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwONYo0NjKca",
        "outputId": "63e92fc5-2197-4022-c74e-d48743ad4825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.9964 - loss: 0.0237 - val_accuracy: 0.9500 - val_loss: 0.1705\n",
            "Epoch 2/5\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.9975 - loss: 0.0187 - val_accuracy: 0.9493 - val_loss: 0.1812\n",
            "Epoch 3/5\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.9985 - loss: 0.0121 - val_accuracy: 0.9521 - val_loss: 0.1905\n",
            "Epoch 4/5\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.9972 - loss: 0.0131 - val_accuracy: 0.9500 - val_loss: 0.1883\n",
            "Epoch 5/5\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9982 - loss: 0.0102 - val_accuracy: 0.9528 - val_loss: 0.1991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Avaliação do modelo"
      ],
      "metadata": {
        "id": "gLE2D3OfkfJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Perda: {loss}, Acurácia: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N7CTarUkhRI",
        "outputId": "a82eee59-24ab-4dd8-b419-799505b44824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 182ms/step - accuracy: 0.9554 - loss: 0.1663\n",
            "Perda: 0.19907745718955994, Acurácia: 0.9527778029441833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Salvar o modelo"
      ],
      "metadata": {
        "id": "-Hh3xnDMBj-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"br_fake_news_predict_model.keras\")"
      ],
      "metadata": {
        "id": "jRHqOJZgBmza"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}